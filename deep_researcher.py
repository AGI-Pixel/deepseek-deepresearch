import time
from typing import List, Dict, Any, Optional
from search_tool import ArxivSearchTool, SearchResult
from llm import LLM

class DeepResearcher:
    def __init__(self, llm_model: str = "gpt-4o"):
        self.llm = LLM(llm_model)
        self.search_tool = ArxivSearchTool()
        self.citations = {}  # citationç¼–å·åˆ°ç»“æœçš„æ˜ å°„
        self.citation_counter = 0
        self.max_rounds = 5  # æœ€å¤šæœç´¢è½®æ•°
        
    def research(self, user_question: str) -> str:
        """
        æ‰§è¡Œæ·±åº¦ç ”ç©¶ï¼Œå®Œå…¨åŸºäºsearch_help.htmlçš„æµç¨‹å’Œprompt
        """
        print(f"ğŸ”¬ å¼€å§‹æ·±åº¦ç ”ç©¶: {user_question}")
        print("=" * 50)
        
        current_date = time.strftime("%Y-%m-%d, %A")
        
        # ç¬¬ä¸€æ­¥ï¼šåˆæ­¥æ€è€ƒå’Œè§„åˆ’
        print("ğŸ§  ç¬¬ä¸€æ­¥ï¼šé€æ­¥æ€è€ƒå’Œæ¨ç†")
        initial_analysis = self._initial_thinking(user_question, current_date)
        print(initial_analysis)
        
        all_search_results = []
        search_round = 1
        current_queries = None
        
        # ä»åˆæ­¥åˆ†æä¸­æå–ç¬¬ä¸€è½®æœç´¢æŸ¥è¯¢
        first_queries = self._extract_first_search_queries(user_question, initial_analysis)
        current_queries = first_queries
        
        # å¼€å§‹è¿­ä»£æœç´¢å¾ªç¯
        while current_queries and search_round <= self.max_rounds:
            print(f"\nğŸ” ç¬¬{search_round}è½®æœç´¢")
            print(f"æœç´¢æŸ¥è¯¢: {current_queries}")
            
            # æ‰§è¡Œå½“å‰è½®æœç´¢
            round_results = self._conduct_search_round(current_queries)
            all_search_results.extend(round_results)
            
            # åˆ†æå½“å‰è½®ç»“æœå¹¶ç”Ÿæˆåç»­æŸ¥è¯¢
            analysis_and_queries = self._analyze_results_and_generate_queries(
                user_question, all_search_results, search_round
            )
            
            print(f"ğŸ“Š ç¬¬{search_round}è½®åˆ†æï¼š")
            print(analysis_and_queries['analysis'])
            
            # æ£€æŸ¥æ˜¯å¦æœ‰åç»­æŸ¥è¯¢
            next_queries = analysis_and_queries.get('next_queries')
            if next_queries:
                print(f"ğŸ”® å‘ç°éœ€è¦è¿›ä¸€æ­¥æœç´¢: {next_queries}")
                current_queries = next_queries
                search_round += 1
            else:
                print("âœ… æœç´¢å®Œæˆï¼Œæœªå‘ç°éœ€è¦è¿›ä¸€æ­¥ç ”ç©¶çš„é—®é¢˜")
                break
        
        # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        print(f"\nğŸ“ åŸºäº{len(all_search_results)}ç¯‡è®ºæ–‡ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...")
        final_answer = self._generate_final_answer(user_question, all_search_results, search_round)
        
        return final_answer
    
    def _initial_thinking(self, question: str, current_date: str) -> str:
        """
        åˆæ­¥æ€è€ƒå’Œæ¨ç†ï¼Œå®Œå…¨å‚è€ƒsearch_help.htmlçš„é£æ ¼
        """
        thinking_prompt = f"""å½“å‰æ—¥æœŸæ˜¯{current_date}ã€‚ä½ çš„ä¸»è¦ä»»åŠ¡æ˜¯è§£å†³ç”¨æˆ·çš„é—®é¢˜ï¼Œæ ¹æ®éœ€è¦åˆ©ç”¨é€‚å½“çš„å·¥å…·ã€‚

[æ ¸å¿ƒæŒ‡ä»¤ï¼šè¯­è¨€ä¸€è‡´æ€§]
ä½ å¿…é¡»ç”¨ä¸ç”¨æˆ·é—®é¢˜ç›¸åŒçš„è¯­è¨€å†™ä½ çš„æ•´ä¸ªå›ç­”ã€‚
å¦‚æœç”¨æˆ·ç”¨ä¸­æ–‡æé—®ï¼Œä½ å¿…é¡»ç”¨ä¸­æ–‡æ€è€ƒå’Œå†™ä½œã€‚

ä½ å¿…é¡»é¦–å…ˆè¿›è¡Œé€æ­¥ã€ä¸¥æ ¼çš„æ€è€ƒå’Œæ¨ç†ï¼Œç„¶åè§„åˆ’æœç´¢ç­–ç•¥ã€‚

ç”¨æˆ·çš„é—®é¢˜æ˜¯ï¼š{question}

è¯·è¿›è¡Œé€æ­¥åˆ†æï¼š
1. ç†è§£é—®é¢˜çš„æ ¸å¿ƒè¦æ±‚
2. åˆ†è§£é—®é¢˜çš„å„ä¸ªå…³é”®æ–¹é¢
3. è¯†åˆ«éœ€è¦æœç´¢çš„å…³é”®ä¿¡æ¯ç‚¹
4. åˆ¶å®šæœç´¢ç­–ç•¥

è¯·è¯¦ç»†åˆ†æå¹¶è¯´æ˜ä½ çš„æ¨ç†è¿‡ç¨‹ï¼š"""
        
        try:
            return self.llm.response(thinking_prompt)
        except Exception as e:
            return f"åˆæ­¥åˆ†æå¤±è´¥: {e}"
    
    def _extract_first_search_queries(self, question: str, analysis: str) -> List[str]:
        """
        ä»åˆæ­¥åˆ†æä¸­æå–ç¬¬ä¸€è½®æœç´¢æŸ¥è¯¢
        """
        query_prompt = f"""åŸºäºä»¥ä¸‹é—®é¢˜å’Œåˆ†æï¼Œç”Ÿæˆç¬¬ä¸€è½®arXivæœç´¢æŸ¥è¯¢ï¼š

é—®é¢˜ï¼š{question}

åˆ†æï¼š{analysis}

ç”Ÿæˆè¦æ±‚ï¼ˆä¸¥æ ¼éµå¾ªsearch_help.htmlçš„è§„åˆ™ï¼‰ï¼š
- ç”¨"||"åˆ†éš”ä¸åŒæŸ¥è¯¢ï¼Œä¾‹å¦‚ï¼š"deep learning||neural networks||transformer"
- ä½¿ç”¨é€šç”¨çš„ã€æœç´¢å¼•æ“å‹å¥½çš„ã€æ˜“äºæ£€ç´¢çš„å…³é”®è¯
- é¿å…ç›¸å¯¹æˆ–æ¨¡ç³Šæœ¯è¯­
- ä¿æŒæŸ¥è¯¢ç®€çŸ­ï¼Œå»é™¤åŠ©è¯ã€è¿è¯å’Œç–‘é—®è¯
- ä¸»è¦ä½¿ç”¨å…³é”®è¯ç»„åˆï¼ˆç©ºæ ¼åˆ†éš”ï¼‰ï¼Œä¸è¶…è¿‡15ä¸ªå­—ç¬¦
- é¿å…ç‰¹æ®Šæ ‡ç‚¹ç¬¦å·
- å¦‚æœæ¶‰åŠå¤šä¸ªå®ä½“æˆ–å­é—®é¢˜ï¼Œåˆ†æ‹†ä¸ºå•ç‹¬æŸ¥è¯¢
- ç”Ÿæˆ1-5ä¸ªæŸ¥è¯¢

è¯·åªè¿”å›æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œæ— å…¶ä»–å†…å®¹ï¼š"""
        
        try:
            response = self.llm.response(query_prompt)
            queries = [q.strip() for q in response.split('||') if q.strip()]
            return queries[:5]
        except Exception as e:
            print(f"æå–æŸ¥è¯¢å¤±è´¥: {e}")
            return [question]  # å›é€€æ–¹æ¡ˆ
    
    def _conduct_search_round(self, queries: List[str]) -> List[SearchResult]:
        """
        æ‰§è¡Œä¸€è½®æœç´¢
        """
        round_results = []
        
        for query in queries:
            try:
                results = self.search_tool.search_papers([query], max_results=5)
                
                # ä¸ºç»“æœåˆ†é…citation
                for result in results:
                    self.citation_counter += 1
                    citation_key = f"citation:{self.citation_counter}"
                    self.citations[citation_key] = result
                    result.citation = citation_key
                
                round_results.extend(results)
                print(f"  ğŸ“„ '{query}': {len(results)}ç¯‡è®ºæ–‡")
                
            except Exception as e:
                print(f"  âŒ '{query}': {e}")
        
        return round_results
    
    def _analyze_results_and_generate_queries(self, question: str, results: List[SearchResult], round_num: int) -> Dict[str, Any]:
        """
        åˆ†ææœç´¢ç»“æœå¹¶è‡ªåŠ¨ç”Ÿæˆåç»­æŸ¥è¯¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
        è¿™æ˜¯å…³é”®ï¼šLLMè‡ªåŠ¨åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­æœç´¢
        """
        if not results:
            return {'analysis': 'æœ¬è½®æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡ã€‚', 'next_queries': None}
        
        # æ„å»ºæœç´¢ç»“æœä¿¡æ¯
        results_text = self._format_search_results(results)
        
        # å…³é”®promptï¼šè®©LLMåˆ†æå¹¶è‡ªåŠ¨å†³å®šæ˜¯å¦ç”Ÿæˆåç»­æŸ¥è¯¢
        analysis_prompt = f"""åŸºäºä»¥ä¸‹ç¬¬{round_num}è½®arXivæœç´¢ç»“æœåˆ†æé—®é¢˜ï¼š{question}

æœç´¢ç»“æœï¼š
{results_text}

è¯·æä¾›ï¼š
1. å¯¹å½“å‰æœç´¢ç»“æœçš„åˆ†æ
2. åŸºäºç°æœ‰ä¿¡æ¯å¯¹é—®é¢˜çš„å›ç­”
3. **é‡è¦**ï¼šå¦‚æœå½“å‰ä¿¡æ¯ä¸è¶³ä»¥å®Œæ•´å›ç­”é—®é¢˜ï¼Œæˆ–å‘ç°éœ€è¦æ·±å…¥ç ”ç©¶çš„æ–°æ–¹å‘ï¼Œè¯·ç”Ÿæˆ2-3ä¸ªåç»­æœç´¢æŸ¥è¯¢

æ ¼å¼è¦æ±‚ï¼š
åˆ†æï¼š[ä½ çš„åˆ†æå†…å®¹]

åç»­æŸ¥è¯¢ï¼š[å¦‚æœéœ€è¦ç»§ç»­æœç´¢ï¼Œç”¨"||"åˆ†éš”æŸ¥è¯¢ï¼Œä¾‹å¦‚ï¼š"query1||query2||query3"ã€‚å¦‚æœä¸éœ€è¦ç»§ç»­æœç´¢ï¼Œå†™"æ— "]

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼š"""
        
        try:
            response = self.llm.response(analysis_prompt)
            
            # è§£æå“åº”ï¼Œæå–åˆ†æå’Œåç»­æŸ¥è¯¢
            analysis_part = ""
            next_queries = None
            
            if "åç»­æŸ¥è¯¢ï¼š" in response:
                parts = response.split("åç»­æŸ¥è¯¢ï¼š")
                analysis_part = parts[0].replace("åˆ†æï¼š", "").strip()
                query_part = parts[1].strip()
                
                if query_part and query_part != "æ— " and "æ— " not in query_part:
                    next_queries = [q.strip() for q in query_part.split('||') if q.strip()]
            else:
                analysis_part = response
            
            return {
                'analysis': analysis_part,
                'next_queries': next_queries
            }
            
        except Exception as e:
            return {
                'analysis': f"åˆ†æå¤±è´¥: {e}",
                'next_queries': None
            }
    
    def _format_search_results(self, results: List[SearchResult]) -> str:
        """
        æ ¼å¼åŒ–æœç´¢ç»“æœï¼Œå‚è€ƒsearch_help.htmlæ ¼å¼ï¼Œå¹¶æ§åˆ¶é•¿åº¦
        """
        formatted_text = ""
        for i, result in enumerate(results):
            citation = getattr(result, 'citation', f'citation:{i+1}')
            # é™åˆ¶æ¯ä¸ªè®ºæ–‡æ‘˜è¦é•¿åº¦
            snippet = result.snippet[:500] + "..." if len(result.snippet) > 500 else result.snippet
            
            paper_info = f"""[paper {i} begin]
[paper title]{result.title}
[paper url]{result.url}
[paper date published]{result.date_published}
[paper authors]{', '.join((result.authors or [])[:5])}  # æœ€å¤šæ˜¾ç¤º5ä¸ªä½œè€…
[paper snippet begin]
{snippet}
[paper snippet end]
[paper {i} end]

"""
            # å¦‚æœæ€»é•¿åº¦è¶…è¿‡80kå­—ç¬¦ï¼Œåœæ­¢æ·»åŠ æ›´å¤šè®ºæ–‡
            if len(formatted_text + paper_info) > 80000:
                formatted_text += "\n[æ›´å¤šè®ºæ–‡ä¿¡æ¯å·²çœç•¥ï¼Œé¿å…å†…å®¹è¿‡é•¿]\n"
                break
            formatted_text += paper_info
            
        return formatted_text
    
    def _generate_final_answer(self, question: str, all_results: List[SearchResult], total_rounds: int) -> str:
        """
        ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ - åˆ†æ­¥å¤„ç†é¿å…é•¿ä¸Šä¸‹æ–‡é—®é¢˜
        """
        if not all_results:
            return "æŠ±æ­‰ï¼Œæœªæ‰¾åˆ°ç›¸å…³çš„å­¦æœ¯è®ºæ–‡æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
        
        # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆæ ¸å¿ƒç ”ç©¶æŠ¥å‘Šï¼ˆç²¾ç®€è®ºæ–‡ä¿¡æ¯é¿å…è¶…é•¿ï¼‰
        core_report = self._generate_core_report(question, all_results)
        
        # ç¬¬äºŒæ­¥ï¼šå•ç‹¬ç”Ÿæˆå¼•ç”¨ç´¢å¼•ï¼ˆä¸ä¾èµ–LLMï¼‰
        citation_index = self._generate_citation_index(all_results)
        
        # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats_section = self._generate_stats_section(all_results, total_rounds)
        
        # ç»„åˆæœ€ç»ˆæŠ¥å‘Š
        final_report = f"""{core_report}

---

{stats_section}

### ğŸ“– è®ºæ–‡å¼•ç”¨ç´¢å¼•
{citation_index}

---

*æœ¬æŠ¥å‘ŠåŸºäºarXivå­¦æœ¯æ•°æ®åº“çš„å®æ—¶æœç´¢ç»“æœç”Ÿæˆï¼Œç”±DeepSeek-v3å¤§è¯­è¨€æ¨¡å‹åˆ†ææ•´ç†ã€‚*
"""
        
        return final_report
    
    def _generate_core_report(self, question: str, all_results: List[SearchResult]) -> str:
        """
        ç”Ÿæˆæ ¸å¿ƒç ”ç©¶æŠ¥å‘Š - ä½¿ç”¨ç²¾ç®€çš„è®ºæ–‡ä¿¡æ¯
        """
        # ç²¾ç®€è®ºæ–‡ä¿¡æ¯ï¼Œåªä¿ç•™å…³é”®å†…å®¹
        simplified_papers = []
        for i, result in enumerate(all_results[:20], 1):  # æœ€å¤šå¤„ç†20ç¯‡è®ºæ–‡
            citation = getattr(result, 'citation', f'citation:{i}')
            simplified_papers.append(f"""
[{citation}] {result.title}
å‘å¸ƒ: {result.date_published} | ä½œè€…: {', '.join((result.authors or [])[:2])}{'ç­‰' if len(result.authors or []) > 2 else ''}
æ‘˜è¦: {result.snippet[:200]}{'...' if len(result.snippet) > 200 else ''}
""")
        
        papers_text = '\n'.join(simplified_papers)
        
        # ç²¾ç®€çš„promptï¼Œä¸“æ³¨äºæ ¸å¿ƒåˆ†æ
        report_prompt = f"""åŸºäºä»¥ä¸‹arXivè®ºæ–‡ï¼Œä¸ºæŠ€æœ¯ç ”å‘äººå‘˜ç”Ÿæˆä¸“ä¸šçš„å­¦æœ¯ç ”ç©¶æŠ¥å‘Šã€‚

ç ”ç©¶é—®é¢˜ï¼š{question}

ç›¸å…³è®ºæ–‡ï¼ˆç²¾é€‰ï¼‰ï¼š
{papers_text}

è¯·æŒ‰ä»¥ä¸‹ç»“æ„ç”ŸæˆæŠ¥å‘Šï¼š

# å­¦æœ¯ç ”ç©¶æŠ¥å‘Š

## 1. æ‰§è¡Œæ‘˜è¦
ç®€æ˜å›ç­”é—®é¢˜ï¼Œæ€»ç»“æ ¸å¿ƒå‘ç°å’Œå¯¹ç ”å‘å·¥ä½œçš„å¯ç¤ºã€‚

## 2. æŠ€æœ¯èƒŒæ™¯ä¸ç°çŠ¶
åˆ†æé—®é¢˜çš„å­¦æœ¯ç ”ç©¶ç°çŠ¶ã€å…³é”®æŒ‘æˆ˜å’Œå‘å±•è½¨è¿¹ã€‚

## 3. æ ¸å¿ƒæŠ€æœ¯åˆ†æ
åŸºäºè®ºæ–‡è¯æ®åˆ†æä¸»è¦æŠ€æœ¯æ–¹æ³•ã€åˆ›æ–°ç‚¹å’Œå®éªŒç»“æœã€‚

## 4. å¯¹æ¯”åˆ†æä¸è¯„ä¼°
æ¯”è¾ƒä¸åŒæ–¹æ³•çš„ä¼˜ç¼ºç‚¹ã€é€‚ç”¨åœºæ™¯å’ŒæŠ€æœ¯é™åˆ¶ã€‚

## 5. å®è·µåº”ç”¨æŒ‡å¯¼
æä¾›å·¥ç¨‹å®ç°å»ºè®®ã€æŠ€æœ¯é€‰å‹å’Œé£é™©è¯„ä¼°ã€‚

## 6. å‰æ²¿è¶‹åŠ¿ä¸å‘å±•
æ€»ç»“æœ€æ–°åŠ¨æ€ã€æœªæ¥è¶‹åŠ¿å’ŒæŠ€æœ¯è·¯çº¿å»ºè®®ã€‚

è¦æ±‚ï¼š
- ä½¿ç”¨[citation:x]æ ¼å¼å¼•ç”¨è®ºæ–‡
- æä¾›å…·ä½“æŠ€æœ¯ç»†èŠ‚
- é¢å‘ç ”å‘äººå‘˜ï¼Œçªå‡ºå®ç”¨æ€§
- ç”¨ä¸­æ–‡æ’°å†™ï¼Œä¿æŒä¸“ä¸šæ€§

è¯·ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šï¼š"""
        
        try:
            return self.llm.response(report_prompt)
        except Exception as e:
            # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œç”ŸæˆåŸºç¡€æŠ¥å‘Š
            return self._generate_fallback_report(question, all_results, str(e))
    
    def _generate_fallback_report(self, question: str, all_results: List[SearchResult], error: str) -> str:
        """
        ç”Ÿæˆå¤‡ç”¨æŠ¥å‘Šï¼ˆå½“LLMè°ƒç”¨å¤±è´¥æ—¶ï¼‰
        """
        return f"""# å­¦æœ¯ç ”ç©¶æŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦
åŸºäºæœç´¢åˆ°çš„{len(all_results)}ç¯‡arXivè®ºæ–‡ï¼Œé’ˆå¯¹"{question}"è¿›è¡Œäº†ç³»ç»Ÿæ€§æ–‡çŒ®è°ƒç ”ã€‚

## æœç´¢ç»“æœæ¦‚è§ˆ
æœ¬æ¬¡ç ”ç©¶å…±æ£€ç´¢äº†{len(all_results)}ç¯‡ç›¸å…³å­¦æœ¯è®ºæ–‡ï¼Œæ¶µç›–äº†ä»¥ä¸‹æ—¶é—´èŒƒå›´ï¼š
- æœ€æ—©è®ºæ–‡ï¼š{min([r.date_published for r in all_results if r.date_published], default='æœªçŸ¥')}
- æœ€æ–°è®ºæ–‡ï¼š{max([r.date_published for r in all_results if r.date_published], default='æœªçŸ¥')}

## å…³é”®å‘ç°
é€šè¿‡æ–‡çŒ®è°ƒç ”å‘ç°äº†ä»¥ä¸‹å…³é”®è®ºæ–‡ï¼š

{self._format_key_findings(all_results[:10])}

## æŠ€æœ¯è¯´æ˜
ç”±äºæ¨¡å‹å¤„ç†é•¿æ–‡æœ¬æ—¶é‡åˆ°æŠ€æœ¯é™åˆ¶ï¼ˆ{error}ï¼‰ï¼Œæœ¬æŠ¥å‘Šé‡‡ç”¨äº†ç²¾ç®€æ¨¡å¼ã€‚
å®Œæ•´çš„æŠ€æœ¯åˆ†æè¯·å‚è€ƒä¸‹æ–¹çš„è®ºæ–‡å¼•ç”¨ç´¢å¼•ï¼Œæ¯ç¯‡è®ºæ–‡éƒ½æä¾›äº†è¯¦ç»†çš„æ‘˜è¦å’Œé“¾æ¥ã€‚

## å»ºè®®
1. ä¼˜å…ˆå…³æ³¨è¿‘æœŸå‘è¡¨çš„é«˜ç›¸å…³æ€§è®ºæ–‡
2. æ·±å…¥ç ”ç©¶è¢«é¢‘ç¹å¼•ç”¨çš„ç»å…¸è®ºæ–‡
3. å…³æ³¨ä¸åŒç ”ç©¶å›¢é˜Ÿçš„æ–¹æ³•å¯¹æ¯”"""
    
    def _format_key_findings(self, results: List[SearchResult]) -> str:
        """æ ¼å¼åŒ–å…³é”®å‘ç°"""
        findings = ""
        for i, result in enumerate(results, 1):
            citation = getattr(result, 'citation', f'citation:{i}')
            findings += f"\n**{citation}** {result.title}\n*å‘å¸ƒäº {result.date_published}*\n{result.snippet[:150]}{'...' if len(result.snippet) > 150 else ''}\n"
        return findings
    
    def _generate_stats_section(self, all_results: List[SearchResult], total_rounds: int) -> str:
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯éƒ¨åˆ†"""
        unique_dates = list(set([r.date_published for r in all_results if r.date_published]))
        unique_categories = list(set([cat for r in all_results for cat in (r.categories or [])]))
        
        return f"""## ğŸ“Š ç ”ç©¶æ•°æ®ç»Ÿè®¡

### ğŸ” æœç´¢æ¦‚å†µ
- **æœç´¢è½®æ•°**: {total_rounds} è½®è¿­ä»£æœç´¢
- **æ£€ç´¢è®ºæ–‡**: {len(all_results)} ç¯‡å­¦æœ¯è®ºæ–‡
- **æ—¶é—´è¦†ç›–**: {min(unique_dates, default='æœªçŸ¥')} è‡³ {max(unique_dates, default='æœªçŸ¥')}
- **ç ”ç©¶é¢†åŸŸ**: {len(unique_categories)} ä¸ªç ”ç©¶æ–¹å‘

### ğŸ“š ä¸»è¦ç ”ç©¶é¢†åŸŸ
{self._format_categories(unique_categories)}"""
    
    def _generate_citation_index(self, all_results: List[SearchResult]) -> str:
        """ç”Ÿæˆå¯ç‚¹å‡»çš„è®ºæ–‡å¼•ç”¨ç´¢å¼•"""
        index_text = ""
        for i, result in enumerate(all_results, 1):
            citation = getattr(result, 'citation', f'citation:{i}')
            # æå–citationç¼–å·
            citation_num = citation.replace('citation:', '')
            
            authors_text = ', '.join(result.authors[:3] if result.authors else []) + ('ç­‰' if len(result.authors or []) > 3 else '')
            
            index_text += f"""
**[{citation}]** {result.title}  
*{authors_text}* | {result.date_published} | [{result.url}]({result.url})  
{result.snippet[:150]}{'...' if len(result.snippet) > 150 else ''}
"""
        
        return index_text
    
    def _format_categories(self, categories: List[str]) -> str:
        """æ ¼å¼åŒ–ç ”ç©¶é¢†åŸŸåˆ†ç±»"""
        if not categories:
            return "- æœªåˆ†ç±»"
        
        # æŒ‰é¢‘ç‡æ’åºå¹¶é™åˆ¶æ˜¾ç¤ºæ•°é‡
        category_text = ""
        for i, cat in enumerate(categories[:8], 1):
            category_text += f"- **{cat}**\n"
        
        if len(categories) > 8:
            category_text += f"- å…¶ä»– {len(categories) - 8} ä¸ªé¢†åŸŸ...\n"
        
        return category_text