#!/usr/bin/env python3
"""
å¯¹æ¯”åˆ†æï¼šä¼ ç»Ÿæ–¹æ³• vs DeepSeek AgentåŸç”Ÿæ¨¡å¼

è¿™ä¸ªè„šæœ¬ç”¨äºç³»ç»Ÿæ€§åœ°å¯¹æ¯”ä¸¤ç§ä¸åŒçš„Deep Researchå®ç°æ–¹å¼ï¼š
1. ä¼ ç»Ÿçš„ç¨‹åºåŒ–è°ƒç”¨æ–¹å¼ (deep_researcher.py)
2. DeepSeek AgentåŸç”Ÿtoolè°ƒç”¨æ–¹å¼ (deep_research_agentic_by_deepseek.py)

é€šè¿‡å¤šä¸ªæµ‹è¯•ç”¨ä¾‹æ¥åˆ†æä¸¤ç§æ–¹æ³•åœ¨æ•ˆç‡ã€å‡†ç¡®æ€§ã€ç”¨æˆ·ä½“éªŒç­‰æ–¹é¢çš„å·®å¼‚ã€‚
"""

import time
import json
from typing import Dict, List, Any
from deep_researcher import DeepResearcher
from deep_research_agentic_by_deepseek import DeepSeekAgenticResearcher

class ApproachComparator:
    """æ–¹æ³•å¯¹æ¯”å™¨ - ç³»ç»Ÿæ€§å¯¹æ¯”ä¸¤ç§ç ”ç©¶æ–¹æ³•"""
    
    def __init__(self):
        self.traditional_researcher = DeepResearcher("deepseek-v3")
        self.agent_researcher = DeepSeekAgenticResearcher("deepseek-v3")
        
        # æµ‹è¯•ç”¨ä¾‹
        self.test_cases = [
            {
                "id": "basic_concept",
                "question": "ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æœºåˆ¶ï¼Ÿ",
                "category": "åŸºç¡€æ¦‚å¿µ",
                "expected_aspects": ["å®šä¹‰", "åŸç†", "åº”ç”¨", "å‘å±•å†ç¨‹"]
            },
            {
                "id": "technical_comparison", 
                "question": "CNNå’ŒTransformeråœ¨è®¡ç®—æœºè§†è§‰ä¸­çš„ä¼˜ç¼ºç‚¹å¯¹æ¯”",
                "category": "æŠ€æœ¯å¯¹æ¯”",
                "expected_aspects": ["æ¶æ„å·®å¼‚", "æ€§èƒ½å¯¹æ¯”", "é€‚ç”¨åœºæ™¯", "è®¡ç®—å¤æ‚åº¦"]
            },
            {
                "id": "frontier_research",
                "question": "å¤§è¯­è¨€æ¨¡å‹çš„æœ€æ–°ä¼˜åŒ–æŠ€æœ¯æœ‰å“ªäº›ï¼Ÿ",
                "category": "å‰æ²¿ç ”ç©¶", 
                "expected_aspects": ["æœ€æ–°è¿›å±•", "æŠ€æœ¯åˆ›æ–°", "æ€§èƒ½æå‡", "æœªæ¥è¶‹åŠ¿"]
            }
        ]
        
    def run_comprehensive_comparison(self) -> Dict[str, Any]:
        """è¿è¡Œå…¨é¢çš„å¯¹æ¯”åˆ†æ"""
        print("ğŸ”¬ å¯åŠ¨å…¨é¢å¯¹æ¯”åˆ†æ")
        print("="*60)
        
        comparison_results = {
            "test_results": [],
            "overall_analysis": {},
            "recommendations": {}
        }
        
        for test_case in self.test_cases:
            print(f"\nğŸ“ æµ‹è¯•ç”¨ä¾‹: {test_case['question']}")
            print(f"ğŸ“‚ ç±»åˆ«: {test_case['category']}")
            print("-" * 50)
            
            # æ‰§è¡Œå¯¹æ¯”æµ‹è¯•
            case_result = self._compare_single_case(test_case)
            comparison_results["test_results"].append(case_result)
            
            print(f"âœ… æµ‹è¯•å®Œæˆ: {test_case['id']}")
        
        # ç”Ÿæˆæ•´ä½“åˆ†æ
        comparison_results["overall_analysis"] = self._generate_overall_analysis(
            comparison_results["test_results"]
        )
        
        # ç”Ÿæˆä½¿ç”¨å»ºè®®
        comparison_results["recommendations"] = self._generate_recommendations(
            comparison_results["overall_analysis"]
        )
        
        return comparison_results
    
    def _compare_single_case(self, test_case: Dict[str, Any]) -> Dict[str, Any]:
        """å¯¹æ¯”å•ä¸ªæµ‹è¯•ç”¨ä¾‹"""
        question = test_case["question"]
        
        # æµ‹è¯•ä¼ ç»Ÿæ–¹æ³•
        print("ğŸ”§ æµ‹è¯•ä¼ ç»Ÿæ–¹æ³•...")
        traditional_result = self._test_traditional_approach(question)
        
        print("ğŸ¤– æµ‹è¯•DeepSeek Agentæ–¹æ³•...")  
        agent_result = self._test_agent_approach(question)
        
        # åˆ†æç»“æœè´¨é‡
        quality_analysis = self._analyze_result_quality(
            traditional_result, agent_result, test_case["expected_aspects"]
        )
        
        return {
            "test_case": test_case,
            "traditional_result": traditional_result,
            "agent_result": agent_result,
            "quality_analysis": quality_analysis
        }
    
    def _test_traditional_approach(self, question: str) -> Dict[str, Any]:
        """æµ‹è¯•ä¼ ç»Ÿæ–¹æ³•"""
        try:
            start_time = time.time()
            
            # é‡ç½®çŠ¶æ€
            self.traditional_researcher.citations = {}
            self.traditional_researcher.citation_counter = 0
            
            result = self.traditional_researcher.research(question)
            end_time = time.time()
            
            return {
                "success": True,
                "result": result,
                "time_cost": end_time - start_time,
                "citations_count": self.traditional_researcher.citation_counter,
                "result_length": len(result),
                "approach": "ä¼ ç»Ÿç¨‹åºåŒ–è°ƒç”¨"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "time_cost": 0,
                "citations_count": 0,
                "result_length": 0,
                "approach": "ä¼ ç»Ÿç¨‹åºåŒ–è°ƒç”¨"
            }
    
    def _test_agent_approach(self, question: str) -> Dict[str, Any]:
        """æµ‹è¯•Agentæ–¹æ³•"""
        try:
            start_time = time.time()
            
            # é‡ç½®çŠ¶æ€
            self.agent_researcher.citations = {}
            self.agent_researcher.citation_counter = 0
            
            result = self.agent_researcher.research(question)
            end_time = time.time()
            
            return {
                "success": True,
                "result": result,
                "time_cost": end_time - start_time,
                "citations_count": len(self.agent_researcher.citations),
                "result_length": len(result),
                "approach": "DeepSeek AgentåŸç”Ÿæ¨¡å¼"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "time_cost": 0,
                "citations_count": 0,
                "result_length": 0,
                "approach": "DeepSeek AgentåŸç”Ÿæ¨¡å¼"
            }
    
    def _analyze_result_quality(self, traditional: Dict, agent: Dict, expected_aspects: List[str]) -> Dict[str, Any]:
        """åˆ†æç»“æœè´¨é‡"""
        quality_metrics = {
            "completeness": {},
            "accuracy": {},
            "structure": {},
            "usability": {}
        }
        
        # å®Œæ•´æ€§åˆ†æ
        if traditional["success"] and agent["success"]:
            trad_coverage = self._calculate_aspect_coverage(traditional["result"], expected_aspects)
            agent_coverage = self._calculate_aspect_coverage(agent["result"], expected_aspects)
            
            quality_metrics["completeness"] = {
                "traditional": trad_coverage,
                "agent": agent_coverage,
                "winner": "agent" if agent_coverage > trad_coverage else "traditional" if trad_coverage > agent_coverage else "tie"
            }
        
        # æ•ˆç‡åˆ†æ
        if traditional["success"] and agent["success"]:
            quality_metrics["efficiency"] = {
                "traditional_time": traditional["time_cost"],
                "agent_time": agent["time_cost"],
                "winner": "agent" if agent["time_cost"] < traditional["time_cost"] else "traditional",
                "time_diff": abs(traditional["time_cost"] - agent["time_cost"])
            }
        
        # ä¿¡æ¯ä¸°å¯Œåº¦åˆ†æ
        quality_metrics["information_richness"] = {
            "traditional_citations": traditional["citations_count"],
            "agent_citations": agent["citations_count"],
            "traditional_length": traditional["result_length"],
            "agent_length": agent["result_length"],
            "winner": "agent" if agent["citations_count"] > traditional["citations_count"] else "traditional"
        }
        
        return quality_metrics
    
    def _calculate_aspect_coverage(self, result: str, expected_aspects: List[str]) -> float:
        """è®¡ç®—å†…å®¹è¦†ç›–åº¦"""
        if not result:
            return 0.0
        
        result_lower = result.lower()
        covered_aspects = 0
        
        for aspect in expected_aspects:
            # ç®€å•çš„å…³é”®è¯åŒ¹é…æ£€æµ‹
            if aspect.lower() in result_lower or self._contains_related_terms(result_lower, aspect.lower()):
                covered_aspects += 1
        
        return covered_aspects / len(expected_aspects) if expected_aspects else 0.0
    
    def _contains_related_terms(self, text: str, aspect: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«ç›¸å…³æœ¯è¯­"""
        related_terms = {
            "å®šä¹‰": ["æ¦‚å¿µ", "æ˜¯ä»€ä¹ˆ", "å®šä¹‰ä¸º", "æŒ‡çš„æ˜¯"],
            "åŸç†": ["å·¥ä½œåŸç†", "æœºåˆ¶", "å¦‚ä½•å·¥ä½œ", "åŸºæœ¬åŸç†"],
            "åº”ç”¨": ["åº”ç”¨åœºæ™¯", "ä½¿ç”¨", "ç”¨äº", "åº”ç”¨åœ¨"],
            "å‘å±•å†ç¨‹": ["å†å²", "å‘å±•", "æ¼”è¿›", "èµ·æº"],
            "æ¶æ„å·®å¼‚": ["ç»“æ„", "æ¶æ„", "æ¨¡å‹", "è®¾è®¡"],
            "æ€§èƒ½å¯¹æ¯”": ["æ€§èƒ½", "æ•ˆæœ", "å‡†ç¡®ç‡", "é€Ÿåº¦"],
            "é€‚ç”¨åœºæ™¯": ["é€‚ç”¨", "åœºæ™¯", "åº”ç”¨", "ä½¿ç”¨"],
            "è®¡ç®—å¤æ‚åº¦": ["å¤æ‚åº¦", "è®¡ç®—é‡", "æ•ˆç‡", "é€Ÿåº¦"],
            "æœ€æ–°è¿›å±•": ["æœ€æ–°", "æ–°æŠ€æœ¯", "æœ€è¿‘", "è¿›å±•"],
            "æŠ€æœ¯åˆ›æ–°": ["åˆ›æ–°", "æ–°æ–¹æ³•", "çªç ´", "æ”¹è¿›"],
            "æ€§èƒ½æå‡": ["æå‡", "æ”¹å–„", "ä¼˜åŒ–", "å¢å¼º"],
            "æœªæ¥è¶‹åŠ¿": ["è¶‹åŠ¿", "æœªæ¥", "æ–¹å‘", "å±•æœ›"]
        }
        
        if aspect in related_terms:
            return any(term in text for term in related_terms[aspect])
        return False
    
    def _generate_overall_analysis(self, test_results: List[Dict]) -> Dict[str, Any]:
        """ç”Ÿæˆæ•´ä½“åˆ†æ"""
        analysis = {
            "success_rates": {},
            "performance_comparison": {},
            "quality_comparison": {},
            "use_case_recommendations": {}
        }
        
        # æˆåŠŸç‡ç»Ÿè®¡
        traditional_successes = sum(1 for r in test_results if r["traditional_result"]["success"])
        agent_successes = sum(1 for r in test_results if r["agent_result"]["success"])
        total_tests = len(test_results)
        
        analysis["success_rates"] = {
            "traditional": traditional_successes / total_tests,
            "agent": agent_successes / total_tests,
            "total_tests": total_tests
        }
        
        # æ€§èƒ½å¯¹æ¯”
        successful_tests = [r for r in test_results if r["traditional_result"]["success"] and r["agent_result"]["success"]]
        
        if successful_tests:
            avg_traditional_time = sum(r["traditional_result"]["time_cost"] for r in successful_tests) / len(successful_tests)
            avg_agent_time = sum(r["agent_result"]["time_cost"] for r in successful_tests) / len(successful_tests)
            
            avg_traditional_citations = sum(r["traditional_result"]["citations_count"] for r in successful_tests) / len(successful_tests)
            avg_agent_citations = sum(r["agent_result"]["citations_count"] for r in successful_tests) / len(successful_tests)
            
            analysis["performance_comparison"] = {
                "average_time": {
                    "traditional": avg_traditional_time,
                    "agent": avg_agent_time,
                    "faster": "agent" if avg_agent_time < avg_traditional_time else "traditional"
                },
                "average_citations": {
                    "traditional": avg_traditional_citations,
                    "agent": avg_agent_citations,
                    "more_comprehensive": "agent" if avg_agent_citations > avg_traditional_citations else "traditional"
                }
            }
        
        return analysis
    
    def _generate_recommendations(self, overall_analysis: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆä½¿ç”¨å»ºè®®"""
        recommendations = {
            "traditional_approach": {
                "best_for": [],
                "advantages": [],
                "limitations": []
            },
            "agent_approach": {
                "best_for": [],
                "advantages": [],
                "limitations": []
            },
            "selection_guide": {}
        }
        
        # åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®
        perf_comp = overall_analysis.get("performance_comparison", {})
        
        # ä¼ ç»Ÿæ–¹æ³•å»ºè®®
        recommendations["traditional_approach"]["advantages"] = [
            "ç»“æ„åŒ–çš„ç ”ç©¶æµç¨‹",
            "å¯é¢„æµ‹çš„æ‰§è¡Œæ­¥éª¤", 
            "æ˜“äºè°ƒè¯•å’Œä¼˜åŒ–",
            "ç¨³å®šçš„è¾“å‡ºæ ¼å¼"
        ]
        
        recommendations["traditional_approach"]["best_for"] = [
            "éœ€è¦æ ‡å‡†åŒ–è¾“å‡ºæ ¼å¼çš„åœºæ™¯",
            "å¯¹æ‰§è¡Œæµç¨‹æœ‰ä¸¥æ ¼è¦æ±‚çš„ç¯å¢ƒ",
            "æ‰¹é‡å¤„ç†å’Œè‡ªåŠ¨åŒ–é›†æˆ"
        ]
        
        recommendations["traditional_approach"]["limitations"] = [
            "ç¼ºä¹çœŸæ­£çš„æ™ºèƒ½å†³ç­–",
            "æœç´¢ç­–ç•¥ç›¸å¯¹å›ºåŒ–",
            "éš¾ä»¥é€‚åº”å¤æ‚å¤šå˜çš„ç ”ç©¶éœ€æ±‚"
        ]
        
        # Agentæ–¹æ³•å»ºè®®
        recommendations["agent_approach"]["advantages"] = [
            "å±•ç°çœŸæ­£çš„AIæ¨ç†èƒ½åŠ›",
            "è‡ªä¸»çš„æœç´¢å†³ç­–",
            "æ›´è‡ªç„¶çš„äº¤äº’ä½“éªŒ",
            "æ¥è¿‘äººç±»ç ”ç©¶è€…çš„æ€è€ƒè¿‡ç¨‹"
        ]
        
        recommendations["agent_approach"]["best_for"] = [
            "æ¢ç´¢æ€§ç ”ç©¶ä»»åŠ¡",
            "éœ€è¦çµæ´»æœç´¢ç­–ç•¥çš„åœºæ™¯",
            "å±•ç¤ºAI Agentèƒ½åŠ›çš„Demo",
            "ç ”ç©¶å¤æ‚æˆ–å¼€æ”¾æ€§é—®é¢˜"
        ]
        
        recommendations["agent_approach"]["limitations"] = [
            "è¾“å‡ºæ ¼å¼å¯èƒ½ä¸å¤Ÿæ ‡å‡†åŒ–",
            "æ‰§è¡Œæ—¶é—´å¯èƒ½æ›´é•¿",
            "éœ€è¦æ›´å¼ºçš„æ¨¡å‹æ¨ç†èƒ½åŠ›",
            "è°ƒè¯•å’Œä¼˜åŒ–ç›¸å¯¹å›°éš¾"
        ]
        
        # é€‰æ‹©æŒ‡å—
        recommendations["selection_guide"] = {
            "choose_traditional_when": [
                "éœ€è¦ç¨³å®šå¯é çš„ç”Ÿäº§ç¯å¢ƒ",
                "å¯¹è¾“å‡ºæ ¼å¼æœ‰ä¸¥æ ¼è¦æ±‚",
                "éœ€è¦å¿«é€Ÿå“åº”çš„åº”ç”¨åœºæ™¯"
            ],
            "choose_agent_when": [
                "å±•ç¤ºAIèƒ½åŠ›å’ŒæŠ€æœ¯åˆ›æ–°",
                "å¤„ç†å¤æ‚çš„ç ”ç©¶é—®é¢˜",
                "ç”¨æˆ·ä½“éªŒå’Œäº¤äº’æ€§æ›´é‡è¦"
            ]
        }
        
        return recommendations
    
    def generate_comparison_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¯¹æ¯”åˆ†ææŠ¥å‘Š"""
        report = f"""# Deep Research æ–¹æ³•å¯¹æ¯”åˆ†ææŠ¥å‘Š

## ğŸ“Š æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘Šå¯¹æ¯”äº†ä¸¤ç§Deep Researchå®ç°æ–¹æ³•ï¼š
- **ä¼ ç»Ÿç¨‹åºåŒ–è°ƒç”¨æ–¹å¼** (deep_researcher.py)
- **DeepSeek AgentåŸç”Ÿæ¨¡å¼** (deep_research_agentic_by_deepseek.py)

é€šè¿‡{len(results['test_results'])}ä¸ªæµ‹è¯•ç”¨ä¾‹çš„ç³»ç»Ÿæ€§å¯¹æ¯”ï¼Œåˆ†æä¸¤ç§æ–¹æ³•çš„ä¼˜ç¼ºç‚¹å’Œé€‚ç”¨åœºæ™¯ã€‚

## ğŸ” æµ‹è¯•ç»“æœæ¦‚è§ˆ

### æˆåŠŸç‡å¯¹æ¯”
- **ä¼ ç»Ÿæ–¹æ³•**: {results['overall_analysis']['success_rates']['traditional']:.1%}
- **Agentæ–¹æ³•**: {results['overall_analysis']['success_rates']['agent']:.1%}

### æ€§èƒ½å¯¹æ¯”
"""
        
        if "performance_comparison" in results['overall_analysis']:
            perf = results['overall_analysis']['performance_comparison']
            report += f"""
**å¹³å‡æ‰§è¡Œæ—¶é—´**:
- ä¼ ç»Ÿæ–¹æ³•: {perf['average_time']['traditional']:.1f}ç§’
- Agentæ–¹æ³•: {perf['average_time']['agent']:.1f}ç§’
- æ›´å¿«çš„æ–¹æ³•: {perf['average_time']['faster']}

**å¹³å‡å¼•ç”¨æ•°é‡**:
- ä¼ ç»Ÿæ–¹æ³•: {perf['average_citations']['traditional']:.1f}ç¯‡
- Agentæ–¹æ³•: {perf['average_citations']['agent']:.1f}ç¯‡  
- æ›´å…¨é¢çš„æ–¹æ³•: {perf['average_citations']['more_comprehensive']}
"""
        
        # è¯¦ç»†æµ‹è¯•ç»“æœ
        report += "\n## ğŸ“‹ è¯¦ç»†æµ‹è¯•ç»“æœ\n"
        
        for i, result in enumerate(results['test_results'], 1):
            test_case = result['test_case']
            report += f"""
### {i}. {test_case['question']}
**ç±»åˆ«**: {test_case['category']}

**ä¼ ç»Ÿæ–¹æ³•**:
- æˆåŠŸ: {'âœ…' if result['traditional_result']['success'] else 'âŒ'}
- æ—¶é—´: {result['traditional_result']['time_cost']:.1f}ç§’
- å¼•ç”¨: {result['traditional_result']['citations_count']}ç¯‡
- é•¿åº¦: {result['traditional_result']['result_length']:,}å­—ç¬¦

**Agentæ–¹æ³•**:
- æˆåŠŸ: {'âœ…' if result['agent_result']['success'] else 'âŒ'}
- æ—¶é—´: {result['agent_result']['time_cost']:.1f}ç§’  
- å¼•ç”¨: {result['agent_result']['citations_count']}ç¯‡
- é•¿åº¦: {result['agent_result']['result_length']:,}å­—ç¬¦
"""
        
        # ä½¿ç”¨å»ºè®®
        recommendations = results['recommendations']
        report += f"""
## ğŸ¯ ä½¿ç”¨å»ºè®®

### ä¼ ç»Ÿç¨‹åºåŒ–æ–¹æ³• é€‚ç”¨åœºæ™¯:
{chr(10).join(f"- {item}" for item in recommendations['traditional_approach']['best_for'])}

**ä¼˜åŠ¿**:
{chr(10).join(f"- {item}" for item in recommendations['traditional_approach']['advantages'])}

**å±€é™æ€§**:
{chr(10).join(f"- {item}" for item in recommendations['traditional_approach']['limitations'])}

### DeepSeek AgentåŸç”Ÿæ¨¡å¼ é€‚ç”¨åœºæ™¯:
{chr(10).join(f"- {item}" for item in recommendations['agent_approach']['best_for'])}

**ä¼˜åŠ¿**:
{chr(10).join(f"- {item}" for item in recommendations['agent_approach']['advantages'])}

**å±€é™æ€§**:
{chr(10).join(f"- {item}" for item in recommendations['agent_approach']['limitations'])}

## ğŸš€ é€‰æ‹©æŒ‡å—

**é€‰æ‹©ä¼ ç»Ÿæ–¹æ³•å½“**:
{chr(10).join(f"- {item}" for item in recommendations['selection_guide']['choose_traditional_when'])}

**é€‰æ‹©Agentæ–¹æ³•å½“**:
{chr(10).join(f"- {item}" for item in recommendations['selection_guide']['choose_agent_when'])}

## ğŸ”® ç»“è®º

ä¸¤ç§æ–¹æ³•å„æœ‰ä¼˜åŠ¿ï¼Œåº”è¯¥æ ¹æ®å…·ä½“ä½¿ç”¨åœºæ™¯é€‰æ‹©ï¼š

- **ä¼ ç»Ÿæ–¹æ³•**æ›´é€‚åˆç”Ÿäº§ç¯å¢ƒå’Œæ ‡å‡†åŒ–éœ€æ±‚
- **Agentæ–¹æ³•**æ›´é€‚åˆå±•ç¤ºAIèƒ½åŠ›å’Œå¤„ç†å¤æ‚é—®é¢˜

æœªæ¥çš„å‘å±•æ–¹å‘å¯èƒ½æ˜¯ç»“åˆä¸¤ç§æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œæ—¢ä¿æŒAgentçš„æ™ºèƒ½å†³ç­–èƒ½åŠ›ï¼Œåˆæä¾›ä¼ ç»Ÿæ–¹æ³•çš„ç¨³å®šæ€§å’Œå¯æ§æ€§ã€‚

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}*
*æµ‹è¯•ç¯å¢ƒ: DeepSeek-v3æ¨¡å‹*
"""
        
        return report

def main():
    """ä¸»å‡½æ•° - æ‰§è¡Œå®Œæ•´çš„å¯¹æ¯”åˆ†æ"""
    print("ğŸš€ Deep Research æ–¹æ³•å¯¹æ¯”åˆ†æ")
    print("="*60)
    
    # åˆ›å»ºå¯¹æ¯”å™¨
    comparator = ApproachComparator()
    
    # è¿è¡Œå¯¹æ¯”åˆ†æ
    results = comparator.run_comprehensive_comparison()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = comparator.generate_comparison_report(results)
    
    # ä¿å­˜æŠ¥å‘Š
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    filename = f"deep_research_comparison_{timestamp}.md"
    
    with open(filename, "w", encoding="utf-8") as f:
        f.write(report)
    
    print(f"\nğŸ“Š å¯¹æ¯”åˆ†æå®Œæˆ!")
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {filename}")
    
    # è¾“å‡ºç®€è¦ç»“æœ
    print("\nğŸ¯ ç®€è¦ç»“è®º:")
    overall = results['overall_analysis']
    print(f"- ä¼ ç»Ÿæ–¹æ³•æˆåŠŸç‡: {overall['success_rates']['traditional']:.1%}")
    print(f"- Agentæ–¹æ³•æˆåŠŸç‡: {overall['success_rates']['agent']:.1%}")
    
    if "performance_comparison" in overall:
        perf = overall['performance_comparison']
        print(f"- å¹³å‡æ—¶é—´å¯¹æ¯”: ä¼ ç»Ÿ {perf['average_time']['traditional']:.1f}s vs Agent {perf['average_time']['agent']:.1f}s")
        print(f"- å¹³å‡å¼•ç”¨å¯¹æ¯”: ä¼ ç»Ÿ {perf['average_citations']['traditional']:.1f} vs Agent {perf['average_citations']['agent']:.1f}")
    
    print(f"\nğŸ’¡ å»ºè®®æŸ¥çœ‹å®Œæ•´æŠ¥å‘Šä»¥è·å–è¯¦ç»†åˆ†æ: {filename}")

if __name__ == "__main__":
    main()