#!/usr/bin/env python3
"""
Deep Research Agentic - åŸºäºDeepSeekåŸç”ŸToolè°ƒç”¨è§„èŒƒçš„å®ç°

è¿™ä¸ªç‰ˆæœ¬ä¸¥æ ¼éµå¾ªDeepSeekçš„åŸç”Ÿtoolè°ƒç”¨æ ¼å¼ï¼Œå±•ç°çœŸæ­£çš„Agentèƒ½åŠ›ï¼š
- ä½¿ç”¨DeepSeekæ ‡å‡†çš„<|toolâ–callsâ–begin|>æ ¼å¼
- æ¨¡æ‹ŸDeepSeekçš„æ€è€ƒè¿‡ç¨‹å’Œæ¨ç†é“¾
- å±•ç°åŸç”Ÿçš„å¤šè½®æœç´¢å†³ç­–èƒ½åŠ›
- å¯¹æ¯”åˆ†æä¸åŒå®ç°æ–¹å¼çš„ä¼˜åŠ£
"""

import time
import json
import re
from typing import List, Dict, Any, Optional
from search_tool import ArxivSearchTool, SearchResult
from llm import LLM

class DeepSeekAgenticResearcher:
    """
    åŸºäºDeepSeekåŸç”ŸToolè°ƒç”¨è§„èŒƒçš„å­¦æœ¯ç ”ç©¶Agent
    
    æ ¸å¿ƒç‰¹ç‚¹ï¼š
    1. ä½¿ç”¨DeepSeekåŸç”Ÿçš„toolè°ƒç”¨æ ¼å¼
    2. è®©æ¨¡å‹è‡ªä¸»å†³ç­–æœç´¢ç­–ç•¥å’Œç»ˆæ­¢æ¡ä»¶
    3. å®Œå…¨ä¾èµ–æ¨¡å‹çš„æ¨ç†èƒ½åŠ›è¿›è¡Œç ”ç©¶æµç¨‹æ§åˆ¶
    4. æ¨¡æ‹ŸçœŸå®çš„DeepSeek Agentäº¤äº’è¿‡ç¨‹
    """
    
    def __init__(self, llm_model: str = "deepseek-v3"):
        self.llm = LLM(llm_model)
        self.search_tool = ArxivSearchTool()
        self.citations = {}
        self.citation_counter = 0
        self.max_rounds = 5
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯ - æ¨¡æ‹ŸDeepSeekçš„åŸç”Ÿç¯å¢ƒ
        self.system_prompt = self._build_system_prompt()
        
    def _build_system_prompt(self) -> str:
        """æ„å»ºDeepSeekåŸç”Ÿé£æ ¼çš„ç³»ç»Ÿæç¤ºè¯"""
        current_date = time.strftime("%Y-%m-%d, %A")
        
        return f"""The current date is {current_date}. Your primary task is to solve the user's questions, leveraging the appropriate tools as needed.

[Core Instruction: Language Consistency]
You MUST write your entire response in the same language as the user's question.
If the user asks in Chinese, you must think and write in Chinese.

[Core Instruction: Citation Formatting] 
When referencing academic papers from arxiv search results, you must use the format "[citation:x]", where x is the corresponding paper number.

You must first engage in step-by-step, rigorous thinking and reasoning before using the appropriate tool or providing the final answer.

## Tools
You have access to the following tools:

### arxiv_search
Description: Search arXiv for academic papers. Returns a list of relevant research papers with titles, authors, abstracts, and URLs.

Parameters: {{"type": "object", "properties": {{"queries": {{"type": "string", "description": "Generate up to 5 search queries for arXiv based on the research question:\\n\\n- Separate different queries with \\"||\\". For example: \\"deep learning||neural networks||transformer architecture\\".\\n- Use academic terminology and keywords that are commonly used in research papers.\\n- Keep queries focused and specific to improve relevance.\\n- Avoid overly broad or vague terms.\\n- Use English terms as arXiv is primarily in English.\\n- You can search 1 to 5 queries in parallel each time.\\n- If the research question involves multiple aspects or concepts, split them into separate queries.\\n- Do not re-search for queries that have already been searched."}}}}, "required": ["queries"]}}

IMPORTANT: ALWAYS adhere to this exact format for tool use:
<|toolâ–callsâ–begin|><|toolâ–callâ–begin|>tool_call_name<|toolâ–sep|>tool_call_arguments<|toolâ–callâ–end|><|toolâ–callsâ–end|>

Where:
- `tool_call_name` must be "arxiv_search"
- `tool_call_arguments` must be valid JSON that follows the Parameters Schema
- Multiple tool calls can be chained if needed

After using the search tool, you will receive results in this format:
[paper X begin]
[paper title]Title of the paper
[paper url]https://arxiv.org/abs/...
[paper date published]YYYY-MM-DD
[paper authors]Author1, Author2, etc.
[paper snippet begin]
Abstract/summary content...
[paper snippet end]
[paper X end]

Based on these results, you should:
1. Analyze the current search results
2. Determine if additional searches are needed to fully answer the question
3. If more searches are needed, continue with new queries
4. When sufficient information is gathered, provide a comprehensive academic report

Your final report should be structured as a professional academic research report with:
- Executive Summary
- Background and Current State
- Core Technical Analysis  
- Comparative Analysis
- Practical Implementation Guidance
- Future Trends and Development
- Research Statistics
- Citation Index with clickable references"""

    def research(self, user_question: str) -> str:
        """
        æ‰§è¡ŒåŸºäºDeepSeek Agentè§„èŒƒçš„æ·±åº¦ç ”ç©¶
        
        è¿™ä¸ªæ–¹æ³•å°†ç”¨æˆ·é—®é¢˜ç›´æ¥ä¼ é€’ç»™DeepSeekæ¨¡å‹ï¼Œè®©æ¨¡å‹è‡ªä¸»å†³ç­–ï¼š
        1. ä½•æ—¶æœç´¢
        2. æœç´¢ä»€ä¹ˆå†…å®¹  
        3. ä½•æ—¶åœæ­¢æœç´¢
        4. å¦‚ä½•åˆ†æå’Œç»¼åˆç»“æœ
        """
        print(f"ğŸ¤– å¯åŠ¨DeepSeek Agentç ”ç©¶æ¨¡å¼")
        print(f"ğŸ“ ç ”ç©¶é—®é¢˜: {user_question}")
        print("="*60)
        
        # æ„å»ºå®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡
        full_context = f"""{self.system_prompt}

# The user's message is: {user_question}"""
        
        # å¼€å§‹Agentå¯¹è¯å¾ªç¯
        conversation_history = ""
        current_context = full_context
        round_count = 0
        
        while round_count < self.max_rounds:
            round_count += 1
            print(f"\nğŸ”„ Agentæ€è€ƒè½®æ¬¡ {round_count}")
            print("-" * 40)
            
            try:
                # è°ƒç”¨DeepSeekè¿›è¡Œæ¨ç†å’Œå†³ç­–
                response = self.llm.response(current_context)
                print(f"ğŸ§  DeepSeekå“åº”:\n{response[:500]}..." if len(response) > 500 else f"ğŸ§  DeepSeekå“åº”:\n{response}")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«toolè°ƒç”¨
                if self._contains_tool_call(response):
                    print("ğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œæœç´¢...")
                    
                    # è§£æå¹¶æ‰§è¡Œtoolè°ƒç”¨
                    tool_results = self._execute_tool_calls(response)
                    
                    # æ›´æ–°å¯¹è¯å†å²
                    conversation_history += f"\n\nAssistant: {response}"
                    conversation_history += f"\n\nTool Results:\n{tool_results}"
                    
                    # æ›´æ–°ä¸Šä¸‹æ–‡ï¼Œç»§ç»­å¯¹è¯
                    current_context = f"{full_context}{conversation_history}"
                    
                else:
                    # æ²¡æœ‰toolè°ƒç”¨ï¼Œè¯´æ˜Agentè®¤ä¸ºå·²ç»å®Œæˆç ”ç©¶
                    print("âœ… Agentå®Œæˆç ”ç©¶ï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
                    final_report = self._format_final_report(response, user_question)
                    return final_report
                    
            except Exception as e:
                print(f"âŒ Agentå¤„ç†å‡ºé”™: {e}")
                return self._generate_error_report(user_question, str(e))
        
        # è¾¾åˆ°æœ€å¤§è½®æ¬¡é™åˆ¶
        print(f"âš ï¸  è¾¾åˆ°æœ€å¤§è½®æ¬¡é™åˆ¶({self.max_rounds}è½®)ï¼Œç”Ÿæˆå½“å‰ç»“æœ")
        return self._generate_timeout_report(user_question, conversation_history)
    
    def _contains_tool_call(self, response: str) -> bool:
        """æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«DeepSeekæ ¼å¼çš„toolè°ƒç”¨"""
        return "<|toolâ–callsâ–begin|>" in response and "<|toolâ–callsâ–end|>" in response
    
    def _execute_tool_calls(self, response: str) -> str:
        """è§£æå¹¶æ‰§è¡ŒDeepSeekæ ¼å¼çš„toolè°ƒç”¨"""
        try:
            # æå–toolè°ƒç”¨éƒ¨åˆ†
            tool_pattern = r'<\|toolâ–callsâ–begin\|>(.*?)<\|toolâ–callsâ–end\|>'
            tool_matches = re.findall(tool_pattern, response, re.DOTALL)
            
            if not tool_matches:
                return "æœªæ‰¾åˆ°æœ‰æ•ˆçš„å·¥å…·è°ƒç”¨"
            
            all_results = []
            
            for tool_call_block in tool_matches:
                # è§£ææ¯ä¸ªå·¥å…·è°ƒç”¨
                call_pattern = r'<\|toolâ–callâ–begin\|>(.*?)<\|toolâ–sep\|>(.*?)<\|toolâ–callâ–end\|>'
                calls = re.findall(call_pattern, tool_call_block, re.DOTALL)
                
                for tool_name, args_str in calls:
                    if tool_name.strip() == "arxiv_search":
                        # è§£æå‚æ•°
                        try:
                            args = json.loads(args_str.strip())
                            queries_str = args.get("queries", "")
                            queries = [q.strip() for q in queries_str.split("||") if q.strip()]
                            
                            print(f"ğŸ” æ‰§è¡Œæœç´¢æŸ¥è¯¢: {queries}")
                            
                            # æ‰§è¡Œæœç´¢
                            search_results = []
                            for query in queries:
                                results = self.search_tool.search_papers([query], max_results=5)
                                search_results.extend(results)
                            
                            # æ ¼å¼åŒ–æœç´¢ç»“æœä¸ºDeepSeekæœŸæœ›çš„æ ¼å¼
                            formatted_results = self._format_search_results_for_deepseek(search_results)
                            all_results.append(formatted_results)
                            
                        except json.JSONDecodeError as e:
                            print(f"âŒ è§£æå·¥å…·å‚æ•°å¤±è´¥: {e}")
                            all_results.append(f"å·¥å…·è°ƒç”¨å‚æ•°è§£æå¤±è´¥: {args_str}")
            
            return "\n\n".join(all_results) if all_results else "æœç´¢æœªè¿”å›ç»“æœ"
            
        except Exception as e:
            print(f"âŒ æ‰§è¡Œå·¥å…·è°ƒç”¨å¤±è´¥: {e}")
            return f"å·¥å…·è°ƒç”¨æ‰§è¡Œå¤±è´¥: {str(e)}"
    
    def _format_search_results_for_deepseek(self, results: List[SearchResult]) -> str:
        """å°†æœç´¢ç»“æœæ ¼å¼åŒ–ä¸ºDeepSeekæœŸæœ›çš„æ ¼å¼"""
        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡"
        
        formatted_text = ""
        for i, result in enumerate(results):
            # åˆ†é…citationç¼–å·
            self.citation_counter += 1
            citation_key = f"citation:{self.citation_counter}"
            self.citations[citation_key] = result
            result.citation = citation_key
            
            formatted_text += f"""[paper {i} begin]
[paper title]{result.title}
[paper url]{result.url}
[paper date published]{result.date_published}
[paper authors]{', '.join(result.authors[:5] if result.authors else [])}
[paper snippet begin]
{result.snippet[:800]}{'...' if len(result.snippet) > 800 else ''}
[paper snippet end]
[paper {i} end]

"""
        
        return formatted_text
    
    def _format_final_report(self, agent_response: str, question: str) -> str:
        """æ ¼å¼åŒ–Agentçš„æœ€ç»ˆå“åº”ä¸ºæ ‡å‡†ç ”ç©¶æŠ¥å‘Š"""
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        total_papers = len(self.citations)
        unique_dates = list(set([r.date_published for r in self.citations.values() if r.date_published]))
        
        stats_section = f"""

---

## ğŸ“Š ç ”ç©¶æ•°æ®ç»Ÿè®¡

### ğŸ” æœç´¢æ¦‚å†µ
- **æ£€ç´¢è®ºæ–‡**: {total_papers} ç¯‡å­¦æœ¯è®ºæ–‡
- **æ—¶é—´è¦†ç›–**: {min(unique_dates, default='æœªçŸ¥')} è‡³ {max(unique_dates, default='æœªçŸ¥')}

### ğŸ“š è®ºæ–‡å¼•ç”¨ç´¢å¼•
{self._generate_citation_index()}

---

*æœ¬æŠ¥å‘Šç”±DeepSeek AgentåŸç”Ÿèƒ½åŠ›ç”Ÿæˆï¼Œå±•ç°äº†å¤§æ¨¡å‹åœ¨å­¦æœ¯ç ”ç©¶ä¸­çš„è‡ªä¸»å†³ç­–å’Œæ¨ç†èƒ½åŠ›ã€‚*
"""
        
        return agent_response + stats_section
    
    def _generate_citation_index(self) -> str:
        """ç”Ÿæˆå¼•ç”¨ç´¢å¼•"""
        if not self.citations:
            return "æš‚æ— å¼•ç”¨"
        
        index_text = ""
        for citation_key, result in self.citations.items():
            authors_text = ', '.join(result.authors[:3] if result.authors else [])
            if len(result.authors or []) > 3:
                authors_text += 'ç­‰'
            
            index_text += f"""
**[{citation_key}]** {result.title}  
*{authors_text}* | {result.date_published} | [é“¾æ¥]({result.url})  
{result.snippet[:150]}{'...' if len(result.snippet) > 150 else ''}
"""
        
        return index_text
    
    def _generate_error_report(self, question: str, error: str) -> str:
        """ç”Ÿæˆé”™è¯¯æŠ¥å‘Š"""
        return f"""# DeepSeek Agent ç ”ç©¶æŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦
åœ¨ä½¿ç”¨DeepSeek AgentåŸç”Ÿèƒ½åŠ›ç ”ç©¶"{question}"æ—¶é‡åˆ°æŠ€æœ¯é—®é¢˜ã€‚

## é”™è¯¯ä¿¡æ¯
```
{error}
```

## å»ºè®®
1. æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…ç½®
2. ç¡®è®¤æ¨¡å‹è°ƒç”¨å‚æ•°æ­£ç¡®
3. é‡è¯•ç ”ç©¶è¯·æ±‚

---

*DeepSeek Agentæ¨¡å¼ - å±•ç°åŸç”ŸAIæ¨ç†èƒ½åŠ›*"""

    def _generate_timeout_report(self, question: str, history: str) -> str:
        """ç”Ÿæˆè¶…æ—¶æŠ¥å‘Š"""
        return f"""# DeepSeek Agent ç ”ç©¶æŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦
ä½¿ç”¨DeepSeek AgentåŸç”Ÿèƒ½åŠ›ç ”ç©¶"{question}"ï¼Œåœ¨{self.max_rounds}è½®äº¤äº’ä¸­æ”¶é›†äº†ç›¸å…³ä¿¡æ¯ã€‚

## ç ”ç©¶è¿‡ç¨‹æ‘˜è¦
Agentè¿›è¡Œäº†å¤šè½®è‡ªä¸»æœç´¢å’Œåˆ†æï¼Œæ”¶é›†äº†{len(self.citations)}ç¯‡ç›¸å…³è®ºæ–‡ã€‚

## ä¸»è¦å‘ç°
åŸºäºæ”¶é›†çš„å­¦æœ¯è®ºæ–‡ï¼Œä»¥ä¸‹æ˜¯ä¸»è¦ç ”ç©¶å‘ç°ï¼š

{self._generate_citation_index()}

## æŠ€æœ¯è¯´æ˜
Agentåœ¨è§„å®šè½®æ¬¡å†…å®Œæˆäº†ä¿¡æ¯æ”¶é›†ï¼Œå±•ç°äº†DeepSeekæ¨¡å‹çš„è‡ªä¸»ç ”ç©¶èƒ½åŠ›ã€‚

---

*DeepSeek Agentæ¨¡å¼ - åŸç”Ÿå¤šè½®æ¨ç†ä¸å·¥å…·è°ƒç”¨*"""

    def compare_with_traditional_approach(self, question: str) -> Dict[str, Any]:
        """
        å¯¹æ¯”åˆ†æDeepSeek Agentæ¨¡å¼ä¸ä¼ ç»Ÿæ–¹æ³•çš„å·®å¼‚
        
        Returns:
            DictåŒ…å«ä¸¤ç§æ–¹æ³•çš„è¯¦ç»†å¯¹æ¯”ç»“æœ
        """
        print("ğŸ”¬ å¼€å§‹å¯¹æ¯”å®éªŒ...")
        print("="*50)
        
        # ä½¿ç”¨DeepSeek Agentæ¨¡å¼
        start_time = time.time()
        agent_result = self.research(question)
        agent_time = time.time() - start_time
        agent_citations = len(self.citations)
        
        # é‡ç½®çŠ¶æ€ï¼Œå‡†å¤‡ä¼ ç»Ÿæ–¹æ³•æµ‹è¯•
        traditional_citations_backup = self.citations.copy()
        self.citations = {}
        self.citation_counter = 0
        
        # å¯¼å…¥ä¼ ç»Ÿæ–¹æ³•è¿›è¡Œå¯¹æ¯”
        try:
            from deep_researcher import DeepResearcher
            traditional_researcher = DeepResearcher("deepseek-v3")
            
            start_time = time.time()
            traditional_result = traditional_researcher.research(question)
            traditional_time = time.time() - start_time
            traditional_citations = traditional_researcher.citation_counter
            
        except Exception as e:
            print(f"ä¼ ç»Ÿæ–¹æ³•æµ‹è¯•å¤±è´¥: {e}")
            traditional_result = "ä¼ ç»Ÿæ–¹æ³•æµ‹è¯•å¤±è´¥"
            traditional_time = 0
            traditional_citations = 0
        
        # æ¢å¤Agentç»“æœ
        self.citations = traditional_citations_backup
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        comparison = {
            "agent_mode": {
                "approach": "DeepSeekåŸç”ŸAgentæ¨¡å¼",
                "result": agent_result,
                "time_cost": agent_time,
                "citations_count": agent_citations,
                "autonomy_level": "é«˜ - å®Œå…¨è‡ªä¸»å†³ç­–",
                "tool_integration": "åŸç”ŸDeepSeekæ ¼å¼",
                "reasoning_transparency": "é«˜ - å±•ç°å®Œæ•´æ¨ç†è¿‡ç¨‹"
            },
            "traditional_mode": {
                "approach": "ä¼ ç»Ÿç¨‹åºåŒ–è°ƒç”¨",
                "result": traditional_result,
                "time_cost": traditional_time,
                "citations_count": traditional_citations,
                "autonomy_level": "ä¸­ - é¢„è®¾æµç¨‹æ§åˆ¶",
                "tool_integration": "Pythonå‡½æ•°å°è£…",
                "reasoning_transparency": "ä¸­ - ç»“æ„åŒ–æ­¥éª¤å±•ç¤º"
            },
            "analysis": {
                "efficiency_comparison": "Agentæ¨¡å¼" if agent_time < traditional_time else "ä¼ ç»Ÿæ¨¡å¼" + "æ›´é«˜æ•ˆ",
                "information_coverage": "Agentæ¨¡å¼" if agent_citations > traditional_citations else "ä¼ ç»Ÿæ¨¡å¼" + "è¦†ç›–æ›´å…¨é¢",
                "user_experience": "Agentæ¨¡å¼å±•ç°æ›´è‡ªç„¶çš„æ¨ç†è¿‡ç¨‹ï¼Œä¼ ç»Ÿæ¨¡å¼æä¾›æ›´å¯æ§çš„ç»“æ„åŒ–è¾“å‡º",
                "technical_innovation": "Agentæ¨¡å¼æ›´æ¥è¿‘çœŸå®AIåŠ©æ‰‹ä½“éªŒï¼Œå±•ç°åŸç”Ÿæ¨¡å‹èƒ½åŠ›"
            }
        }
        
        return comparison

def test_deepseek_agent():
    """æµ‹è¯•DeepSeek Agentæ¨¡å¼"""
    print("ğŸš€ DeepSeek Agentæ¨¡å¼æµ‹è¯•")
    print("="*50)
    
    # åˆ›å»ºAgentå®ä¾‹
    agent = DeepSeekAgenticResearcher("deepseek-v3")
    
    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "å¸ç¾æ ¼é²è‚½å’ŒäºŒç”²åŒç“œï¼Œå“ªä¸€ä¸ªæ›´åˆ©äºå»¶é•¿å¯¿å‘½",
        "æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
        "Transformeræ¶æ„çš„æ ¸å¿ƒåˆ›æ–°ç‚¹æœ‰å“ªäº›ï¼Ÿ"
    ]
    
    for question in test_questions:
        print(f"\nğŸ“ æµ‹è¯•é—®é¢˜: {question}")
        print("-" * 30)
        
        try:
            result = agent.research(question)
            print(f"âœ… ç ”ç©¶å®Œæˆ")
            print(f"ğŸ“Š æŠ¥å‘Šé•¿åº¦: {len(result):,} å­—ç¬¦")
            print(f"ğŸ“š å¼•ç”¨è®ºæ–‡: {len(agent.citations)} ç¯‡")
            
            # ä¿å­˜ç»“æœ
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"deepseek_agent_test_{timestamp}.md"
            with open(filename, "w", encoding="utf-8") as f:
                f.write(f"# DeepSeek Agentæ¨¡å¼æµ‹è¯•ç»“æœ\n\n")
                f.write(f"**é—®é¢˜**: {question}\n\n")
                f.write(f"**ç”Ÿæˆæ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write(result)
            
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {filename}")
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        
        # é‡ç½®çŠ¶æ€
        agent.citations = {}
        agent.citation_counter = 0
        
        print("\n" + "="*50)

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test_deepseek_agent()
    
    print("\nğŸ”¬ å¯¹æ¯”åˆ†ææµ‹è¯•")
    agent = DeepSeekAgenticResearcher("deepseek-v3")
    
    # æ‰§è¡Œå¯¹æ¯”åˆ†æ
    comparison = agent.compare_with_traditional_approach("ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æœºåˆ¶ï¼Ÿ")
    
    print("\nğŸ“Š å¯¹æ¯”åˆ†æç»“æœ:")
    print(json.dumps(comparison["analysis"], indent=2, ensure_ascii=False))